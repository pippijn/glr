\section{GLR Engine}

A design point: \cite{GLR} uses more globals than I do. My criterion here is
that something should be global (stored in type [[glr]]) if it has meaning
between processing of tokens.  If something is only used during the processing
of a single token, then I make it a parameter where necessary.

Update: I've decided to make [[currentToken]] and [[parserWorklist]]
global because they are needed deep inside of [[glrShiftNonterminal]], though
they are not needed by the intervening levels, and their presence in the
argument lists would therefore only clutter them.

Description of the various lists in play here:

\subsection{[[active_parsers]]}

The active parsers are at the frontier of the parse tree space.  It
\textit{never} contains more than one stack node with a given parse state; I
call this the unique-state property (USP).  If we're about to add a stack node
with the same state as an existing node, we merge them. If it's a shift, we add
another [[leftAdjState]]; if it's a reduction, we add a rule node
\textit{and} another [[leftAdjState]].

Before a token is processed, [[active_parsers]] contains those parsers that
successfully shifted the previous token.  This list is then walked to make the
initial reduction work-list.

Before the shifts are processed, the [[active_parsers]] list is cleared.  As
each shift is processed, the resulting parser is added to [[active_parsers]]
(modulo USP).

\subsection{Path re-examination}

Discussion of path re-examination, called do-limited-reductions by \cite{GLR}:

After thinking about this for some time, I have reached the conclusion that the
only way to handle the problem is to separate the collection of paths from the
iteration over them.

Here are several alternative schemes, and the reasons they don't work:

\begin{enumerate}

  \item \cite{GLR}'s approach of limiting re-examination to those involving the
    new link

    This fails because it does not prevent re-examined paths from appearing in
    the normal iteration also.

  \item Modify \cite{GLR} so the new link can't be used after the re-examination
    is complete

    Then if \textit{another} new link is added, paths involving both new links
    wouldn't be processed.

  \item Further schemes involving controlling which re-examination stage can use
    which links

    Difficult to reason about, unclear a correct scheme exists, short of the
    full-blown path-listing approach I'm going to take.

  \item My first "fix" which assumes there is never more than one path to a
    given parser

    This is \textbf{wrong}. There can be more than one path, even as all such
    paths are labelled the same (namely, with the RHS symbols).  Consider
    grammar $E \to x | E E$ parsing $xxx$: both top-level parses use the $E \to
    E E$ rule, and both arrive at the root parser

\end{enumerate}

So, the solution I will implement is to collect all paths into a list before
processing any of them. During path re-examination, I also will collect paths
into a list, this time only those that involve the new link.

This scheme is clearly correct, since path collection cannot be disrupted by the
process of adding links, and when links are added, exactly the new paths are
collected and processed.  It's easy to see that every path is considered exactly
once.

I've replaced the state work-list (SWL) core used in all previous GLR
implementations with a reduction work-list (RWL) core.  This core is just as
fast, but can be implemented to always avoid the yield-then-merge problem for
acyclic grammars.

Below, parse-tree building activity is marked "TREEBUILD".

Relative to C++ implementation, what is not done:

\begin{itemize}
  \item Table compression
  \item Heavy testing of the mini-LR core
\end{itemize}

<<ml>>=

module Colour = TermColour.Make(TermColour.ANSI)
@
We define our own versions of this exception, so that user code raising
the ones in [[Pervasives]] will not interfere with parser internals.
<<ml>>=
exception End_of_file

@
These Exceptions are part of the public interface.
<<ml>>=
exception ParseError of ParseTables.state_id * (*token*)ParseTables.term_index
exception Located of SourceLocation.t * exn * string

let keep_cancel () =
  UserActions.cancel "keep() returned false"

@
\subsection{GLR engine types}

\subsubsection{Accounting statistics}
<<ml>>=

@
Private mutable statistics.
<<ml>>=
type statistics = {
  mutable numStackNodes		: int;
  mutable maxStackNodes		: int;
  mutable detShift		: int;
  mutable detReduce		: int;
  mutable nondetShift		: int;
  mutable nondetReduce		: int;
}

@
Public immutable statistics.
<<ml>>=
type stats = {
  num_stack_nodes		: int;
  max_stack_nodes		: int;
  det_shift			: int;
  det_reduce			: int;
  nondet_shift			: int;
  nondet_reduce			: int;
}

@
\subsubsection{GLR graph}

Link from one stack node to another.
<<ml>>=
type sibling_link = {
@
  Stack node we're pointing at; [[StackNode.null]] if none.
<<ml>>=
  mutable sib			: stack_node;
@
  Semantic value on this link.
<<ml>>=
  mutable sval			: SemanticValue.t;
@
  Source locations.
<<ml>>=
  mutable start_p		: Lexing.position;
  mutable end_p			: Lexing.position;

  (* possible TODO: yield count *)
}

@
Node in the GLR graph-structured stack; all fields are
mutable because these are stored in a pool for explicit re-use.
<<ml>>=
and stack_node = {
@
  LR parser state when this node is at the top.
<<ml>>=
  mutable state			: ParseTables.state_id;
@
  Pointers to adjacent (to the left) stack nodes.
  Possible TODO: put links into a pool so I can deallocate them.
<<ml>>=
  mutable leftSiblings		: sibling_link list;
@
  Logically first sibling in the sibling list; separated out
  from [[leftSiblings]] for performance reasons.
<<ml>>=
  mutable firstSib		: sibling_link;
@
  Number of sibling links pointing at this node, plus the
  number of worklists this node appears in.
<<ml>>=
  mutable referenceCount	: int;
@
  Number of links we can follow to the left before hitting a node
  that has more than one sibling.
<<ml>>=
  mutable determinDepth		: int;
@
  Position of token that was active when this node was created
  (or pulled from pool); used in yield-then-merge calculations.
<<ml>>=
  mutable column		: int;
}

@
This is a path that has been queued for reduction;
all fields mutable to support pooling
<<ml>>=
type path = {
@
  Array of sibling links, i.e. the path; 0th element is leftmost link.
<<ml>>=
  sibLinks			: sibling_link array;
@
  Corresponding array of symbol ids to interpret svals.
<<ml>>=
  symbols			: ParseTables.symbol_id array;
@
  Rightmost state's id.
<<ml>>=
  mutable startStateId		: ParseTables.state_id;
@
  Production we're going to reduce with.
<<ml>>=
  mutable prodIndex		: int;
@
  Number of right hand side symbols in this production.
<<ml>>=
  mutable rhsLen		: int;
@
  Column from leftmost stack node.
<<ml>>=
  mutable startColumn		: int;
@
  The leftmost stack node itself.
<<ml>>=
  mutable leftEdgeNode		: stack_node;
@
  Next path in dequeueing order.
<<ml>>=
  mutable next			: path option;
}

@
GLR Parser object.
<<ml>>=
type 'result glr = {
@
  Top of priority queue of reduction paths.
<<ml>>=
  mutable top			: path option;
@
  Parse tables from the grammar.
<<ml>>=
  tables			: ParseTables.t;
@
  User-specified actions.
<<ml>>=
  userAct			: 'result UserActions.t;
@
  Treat this as a local variable of [[RWL.processWorklist]], included
  here just to avoid unnecessary repeated allocation.
<<ml>>=
  toPass			: SemanticValue.t array;
@
  Pool of path objects.
<<ml>>=
  pathPool			: path Objpool.t;
@
  Set of topmost parser nodes.
<<ml>>=
  active_parsers		: stack_node Arraystack.t;
@
  Swapped with [[active_parsers]] periodically, for performance reasons.
<<ml>>=
  prev_active			: stack_node Arraystack.t;
@
  Node allocation pool; shared with [[GLR.parseToken]].
<<ml>>=
  stackNodePool			: stack_node Objpool.t;
@
  Current token number.
<<ml>>=
  mutable globalNodeColumn	: int;
@
  Parser action statistics.
<<ml>>=
  stats				: statistics;
}

@
\subsection{Id}

Produce a small unique integer for each physically
different semantic value.
<<ml>>=

module Id = struct

  let unique_table = ref []

  let colourise id =
    Colour.pink ("@" ^ string_of_int id)

  let get obj =
    try
      snd (List.find (fun (addr, _) -> addr == obj) !unique_table)
    with Not_found ->
      let id = colourise (List.length !unique_table) in
      unique_table := (obj, id) :: !unique_table;
      id

  let empty = [(SemanticValue.null, colourise 0)]
  let reset () =
    unique_table := empty

end


module Show = struct

  let array f fmt =
    Array.iter (Format.fprintf fmt "%a;@," f)

  let array f fmt arr =
    Format.fprintf fmt "[|@,%a|]"
      (array f) arr

  let list f fmt =
    List.iter (Format.fprintf fmt "%a;@," f)

  let list f fmt arr =
    Format.fprintf fmt "[@,%a]"
      (list f) arr

  let option f fmt = function
    | None -> Format.fprintf fmt "None"
    | Some v -> Format.fprintf fmt "Some %a" f v

  let rec sibling_link fmt v =
    if v == Obj.magic () then
      Format.fprintf fmt "<null>"
    else
      Format.fprintf fmt "{@,\
                          @[<v2>sib = %a;@]@,}"
        stack_node v.sib

  and stack_node fmt v =
    if v == Obj.magic () then
      Format.fprintf fmt "<null>"
    else
      Format.fprintf fmt "{@,\
                          @[<v2>state = %d;@]@,\
                          @[<v2>leftSiblings = %a;@]@,\
                          @[<v2>firstSib = %a;@]@,\
                          @[<v2>referenceCount = %d;@]@,\
                          @[<v2>determinDepth = %d;@]@,\
                          @[<v2>column = %d;@]@,}"
        (v.state :> int)
        (list sibling_link) v.leftSiblings
        sibling_link v.firstSib
        v.referenceCount
        v.determinDepth
        v.column

  let rec path fmt v =
    if v == Obj.magic () then
      Format.fprintf fmt "<null>"
    else
      Format.fprintf fmt "{@,\
                          @[<v2>sibLinks = %a;@]@,\
                          @[<v2>symbols = %a;@]@,\
                          @[<v2>startStateId = %d;@]@,\
                          @[<v2>prodIndex = %d;@]@,\
                          @[<v2>rhsLen = %d;@]@,\
                          @[<v2>startColumn = %d;@]@,\
                          @[<v2>leftEdgeNode = %a;@]@,\
                          @[<v2>next = %a;@]@,}"
        (array sibling_link) v.sibLinks
        (array Format.pp_print_int) v.symbols
        v.startStateId
        v.prodIndex
        v.rhsLen
        v.startColumn
        stack_node v.leftEdgeNode
        (option path) v.next

end


@
\subsection{Front ends to user code}
<<ml>>=

module User = struct

  open UserActions

@
\subsubsection{Symbol name}
<<ml>>=

  let terminalName userAct tokType =
    Colour.yellow (
      if Options._terminal_names () then
        userAct.terminalName tokType
      else
        userAct.terminalAlias tokType
    )


  let nonterminalName userAct nonterm =
    Colour.yellow (userAct.nonterminalName nonterm)


  let symbolName userAct sym =
    assert (sym <> ParseTables.invalid_symbol);

    if ParseTables.symIsTerm sym then
      terminalName userAct (ParseTables.symAsTerm sym)
    else
      nonterminalName userAct (ParseTables.symAsNonterm sym)


@
\subsubsection{Symbol string representation}
<<ml>>=

  let showTerminalValue userAct term sval =
    Colour.escape (userAct.showTerminalValue term sval)


  let showNontermValue userAct nonterm sval =
    Colour.escape (userAct.showNontermValue nonterm sval)


  let showSemanticValue userAct sym sval =
    assert (sym <> ParseTables.invalid_symbol);

    if ParseTables.symIsTerm sym then
      showTerminalValue userAct (ParseTables.symAsTerm sym) sval
    else
      showNontermValue userAct (ParseTables.symAsNonterm sym) sval


@
\subsubsection{Semantic actions (reduce/merge/keep)}
<<ml>>=

  let reductionAction userAct productionId svals start_p end_p =
    userAct.reductionAction productionId svals start_p end_p


  let mergeAlternativeParses userAct lhsIndex left right =
    if Options._trace_parse () then
      Printf.printf "%s %s\n1: %s %s\n2: %s %s\n"
        (Colour.green "merge")
        (nonterminalName userAct lhsIndex)
        (Id.get left)
        (showNontermValue userAct lhsIndex left)
        (Id.get right)
        (showNontermValue userAct lhsIndex right);

    let merged = userAct.mergeAlternativeParses lhsIndex left right in

    if Options._trace_parse () then
      Printf.printf "=: %s %s\n"
        (Id.get merged)
        (showNontermValue userAct lhsIndex merged);

    merged


  let keepNontermValue userAct lhsIndex sval =
    userAct.keepNontermValue lhsIndex sval


@
\subsubsection{Cloning semantic values for multi-yield}
<<ml>>=

  let duplicateTerminalValue userAct term sval =
    userAct.duplicateTerminalValue term sval


  let duplicateNontermValue userAct nonterm sval =
    userAct.duplicateNontermValue nonterm sval


  let duplicateSemanticValue userAct sym sval =
    assert (sym <> ParseTables.invalid_symbol);


@
    The C++ implementation checks for NULL sval, but that
    doesn't make sense in the ML version, as a zero value
    for an sval is perfectly safe and should be allowed.
<<ml>>=
    let copy =
      if ParseTables.symIsTerm sym then
        duplicateTerminalValue userAct (ParseTables.symAsTerm sym) sval
      else
        duplicateNontermValue userAct (ParseTables.symAsNonterm sym) sval
    in

    if Options._trace_parse () then
      Printf.printf "%s %s%s = %s %s\n"
        (Colour.green "dup")
        (symbolName userAct sym)
        (Id.get sval)
        (Id.get copy)
        (showSemanticValue userAct sym sval);

    copy


@
\subsubsection{Destroying semantic values}

  Before the parser loses them, we give the user a chance
  to do something with the semantic values.
<<ml>>=

  let deallocateTerminalValue userAct term sval =
    userAct.deallocateTerminalValue term sval


  let deallocateNontermValue userAct nonterm sval =
    userAct.deallocateNontermValue nonterm sval


  let deallocateSemanticValue userAct sym sval =
    assert (sym <> ParseTables.invalid_symbol);

    if Options._trace_parse () then
      Printf.printf "%s %s%s %s\n"
        (Colour.green "del")
        (symbolName userAct sym)
        (Id.get sval)
        (showSemanticValue userAct sym sval);

    if ParseTables.symIsTerm sym then
      deallocateTerminalValue userAct (ParseTables.symAsTerm sym) sval
    else
      deallocateNontermValue userAct (ParseTables.symAsNonterm sym) sval


@
\subsubsection{Reclassify token}

  E.g. [[TOK_NAME -> TOK_TYPE_NAME]].
<<ml>>=

  let reclassifyToken userAct lexer token =
    let open Lexerint in
@
    Get original type/sval/sloc.
<<ml>>=
    let tokType = lexer.index token in
    let tokSval = lexer.sval token in
    let tokSloc = lexer.sloc token in
@
    Reclassify type.
<<ml>>=
    let tokType = userAct.reclassifyToken tokType tokSval in
@
    Return all token properties.
<<ml>>=
    tokType, tokSval, tokSloc

end


@
\subsection{Parallel parsers}
<<ml>>=

module SiblingLink = struct

  type t = sibling_link
@
  NULL sibling link.
<<ml>>=
  let null : t = Obj.magic ()

  let create sib sval start_p end_p = { sib; sval; start_p; end_p; }

end


@
\subsection{Single parser node}
<<ml>>=

module StackNode : sig

  type t = stack_node

  val null : t

  val create : unit -> t

  val init : t -> ParseTables.state_id -> unit

  val make
    : 'result glr
    -> ParseTables.state_id
    -> t

  val inc_refcnt : t -> unit
  val dec_refcnt : 'result glr -> t -> unit

  val hasZeroSiblings : t -> bool
  val hasOneSibling : t -> bool

  val getNodeSymbol
    : 'result glr
    -> t
    -> ParseTablesType.symbol_id
  val getLinkTo
    : t
    -> t
    -> SiblingLink.t option
  val getUniqueLink
    : t
    -> SiblingLink.t

  val addFirstSiblingLink_no_refcnt
    : t
    -> t
    -> SemanticValue.t
    -> Lexing.position
    -> Lexing.position
    -> unit
  val addSiblingLink
    : t
    -> t
    -> SemanticValue.t
    -> Lexing.position
    -> Lexing.position
    -> SiblingLink.t

  val computeDeterminDepth : t -> int
  val checkLocalInvariants : t -> bool

end = struct

  type t = stack_node
@
  NULL stack node.
<<ml>>=
  let null : t = Obj.magic ()


  let create () = {
    state          = ParseTables.invalid_state;
    leftSiblings   = [];
    firstSib       =
      SiblingLink.create null SemanticValue.null
        Lexing.dummy_pos Lexing.dummy_pos;
    referenceCount = 0;
    determinDepth  = 0;
    column         = 0;
  }


  let getNodeSymbol glr node =
    ParseTables.getStateSymbol glr.tables node.state


  let inc_refcnt node =
    node.referenceCount <- node.referenceCount + 1


  let rec dec_refcnt glr node =
    assert (node.referenceCount > 0);

    node.referenceCount <- node.referenceCount - 1;

    if false then
      Printf.printf "decrementing node %d to %d\n"
        node.state node.referenceCount;

    if node.referenceCount = 0 then (
      deinit glr node;
      Objpool.dealloc glr.stackNodePool node
    )


  and deinit glr node =
    deallocSemanticValues glr node;
@
    This is implicit in the C++ implementation because [[firstSib.sib]]
    is an [[RCPtr]] in C++.
<<ml>>=
    if node.firstSib.sib != null then
      dec_refcnt glr node.firstSib.sib;

    node.firstSib.sib <- null;

    if Options._accounting () then (
      glr.stats.numStackNodes <- glr.stats.numStackNodes - 1;
    )


  and deallocSemanticValues glr node =
@
    Explicitly deallocate siblings, so I can deallocate their
    semantic values if necessary (this requires knowing the
    associated symbol, which the [[sibling_links]] don't know).
<<ml>>=
    if node.firstSib.sib != null then
      User.deallocateSemanticValue glr.userAct (getNodeSymbol glr node)
        node.firstSib.sval;

    List.iter (fun s ->
      User.deallocateSemanticValue glr.userAct (getNodeSymbol glr node)
        s.sval;
@
      This is implicit in the C++ version, due to [[Owner<>]].
<<ml>>=
      dec_refcnt glr s.sib
    ) node.leftSiblings;

    node.leftSiblings <- []


  let hasZeroSiblings node =
    node.firstSib.sib == null


  let hasOneSibling node =
    node.firstSib.sib != null && node.leftSiblings == []


  let hasMultipleSiblings node =
    node.leftSiblings != []


  let init node state =
    node.state <- state;
    assert (node.leftSiblings == []);
    assert (node.firstSib.sib == null);
    node.referenceCount <- 0;
    node.determinDepth  <- 1


  let make glr state =
    if Options._accounting () then (
      glr.stats.numStackNodes <- glr.stats.numStackNodes + 1;
      if glr.stats.numStackNodes > glr.stats.maxStackNodes then
        glr.stats.maxStackNodes <- glr.stats.numStackNodes;
    );

    let node = Objpool.alloc glr.stackNodePool in
    init node state;
    node.column <- glr.globalNodeColumn;
    node


@
  Add the very first sibling.
<<ml>>=
  let addFirstSiblingLink_no_refcnt node leftSib sval start_p end_p =
    assert (hasZeroSiblings node);
@
    My depth will be my new sibling's depth, plus 1.
<<ml>>=
    node.determinDepth <- leftSib.determinDepth + 1;
@
    We don't have any siblings yet; use embedded
    don't update reference count of [[leftSib]], instead caller must do so.
<<ml>>=
    assert (hasZeroSiblings node);
    node.firstSib.sib <- leftSib;     (* update w/o refcount *)

    node.firstSib.sval <- sval;
    node.firstSib.start_p <- start_p;
    node.firstSib.end_p <- end_p


@
  Pulled out of [[addSiblingLink]] so I can inline addSiblingLink
  without excessive object code bloat; the branch represented by
  the code in this function is much less common.
<<ml>>=
  let addAdditionalSiblingLink node leftSib sval start_p end_p =
@
  There's currently at least one sibling, and now we're adding another;
  right now, no other stack node should point at this one (if it does,
  most likely will catch that when we use the stale info).

  Now there is a second outgoing pointer.
<<ml>>=
    node.determinDepth <- 0;
@
    This was implicit in the C++ version.
<<ml>>=
    inc_refcnt leftSib;

    let link = SiblingLink.create leftSib sval start_p end_p in
    node.leftSiblings <- link :: node.leftSiblings;

    link


@
  Add a new sibling by creating a new link.
<<ml>>=
  let addSiblingLink node leftSib sval start_p end_p =
    if hasZeroSiblings node then (
      addFirstSiblingLink_no_refcnt node leftSib sval start_p end_p;
@
      Manually increment [[leftSib]]'s reference count.
<<ml>>=
      inc_refcnt leftSib;
@
      Pointer to [[firstSib]]..
<<ml>>=
      node.firstSib
    ) else (
@
      As best I can tell, x86 static branch prediction is simply
      "conditional forward branches are assumed not taken", hence
      the uncommon case belongs in the [[else]] branch.
<<ml>>=
      addAdditionalSiblingLink node leftSib sval start_p end_p
    )


  let getUniqueLink node =
    assert (hasOneSibling node);
    node.firstSib


  let getLinkTo node another =
@
    Check first..
<<ml>>=
    if node.firstSib.sib == another then (
      Some node.firstSib
    ) else (
@
      Check rest.
<<ml>>=
      try
        let link = List.find (fun candidate -> candidate.sib == another) node.leftSiblings in
        Some link
      with Not_found ->
        None
    )


  (* printAllocStats goes here *)

  let computeDeterminDepth node =
    if hasZeroSiblings node then (
      1
    ) else if hasOneSibling node then (
@
      It must be equal to sibling's, plus one.
<<ml>>=
      node.firstSib.sib.determinDepth + 1
    ) else (
      assert (hasMultipleSiblings node);
      0
    )


  let checkLocalInvariants node =
    computeDeterminDepth node = node.determinDepth

end


@
\subsection{Path queue management}
<<ml>>=

module Path : sig

  type t = path

  val create
    : 'result glr
    -> ParseTables.state_id
    -> int
    -> int
    -> t

  val delete
    : 'result glr
    -> t
    -> unit

  val ensureRhsLen
    : t
    -> int
    -> bool

  val insert_copy
    : 'result glr
    -> t
    -> StackNode.t
    -> unit

  val dequeue
    : 'result glr
    -> t option

end = struct

  type t = path

  (* stackTraceString *)

  let create glr ssi pi rhsLen =
    let p = Objpool.alloc glr.pathPool in
    p.startStateId <- ssi;
    p.prodIndex <- pi;
    p.rhsLen <- rhsLen;
    p


  let delete glr p =
    Objpool.dealloc glr.pathPool p


@
  Ensure the arrays have at least the given index.
<<ml>>=
  let ensureRhsLen p rhsLen =
    Array.length p.sibLinks >= rhsLen &&
    Array.length p.symbols  >= rhsLen


  let compare_path glr p1 p2 =
    if p1.startColumn > p2.startColumn then (
@
      [[p1]] spans fewer tokens, so it goes first.
<<ml>>=
      -1
    ) else if p2.startColumn > p1.startColumn then (
@
      Same logic.
<<ml>>=
      1
    ) else (
      let tables = glr.tables in
@
      Equal start columns, compare nonterm ids.
<<ml>>=
      let p1NtIndex = ParseTables.getProdInfo_lhsIndex tables p1.prodIndex in
      let p2NtIndex = ParseTables.getProdInfo_lhsIndex tables p2.prodIndex in
@
      Check nonterm order.
<<ml>>=
      let ord1 = ParseTables.getNontermOrdinal tables p1NtIndex in
      let ord2 = ParseTables.getNontermOrdinal tables p2NtIndex in

      ord1 - ord2
    )


@
  Find the link where we want to insert the path.
<<ml>>=
  let rec search_pos glr p prev =
    match prev.next with
    | Some next when compare_path glr p next < 0 ->
        search_pos glr p next
    | _ ->
        prev


  let insert_copy glr src leftEdge =
    let rhsLen = src.rhsLen in

@
    Make a new node.
<<ml>>=
    let p = create glr src.startStateId src.prodIndex rhsLen in

@
    Fill in left edge info.
<<ml>>=
    p.leftEdgeNode <- leftEdge;
    p.startColumn  <- leftEdge.column;

@
    Copy path info.
<<ml>>=
    for i = 0 to rhsLen - 1 do
      p.sibLinks.(i) <- src.sibLinks.(i);
      p.symbols .(i) <- src.symbols .(i);
    done;

@
    Find proper place to insert new path.
<<ml>>=
    match glr.top with
    | None ->
@
        Prepend.
<<ml>>=
        p.next <- None;
        glr.top <- Some p;

    | Some top ->
        if compare_path glr p top < 0 then (
          p.next <- glr.top;
          glr.top <- Some p;
        ) else (
@
          Search.
<<ml>>=
          let prev = search_pos glr p top in

@
          Insert.
<<ml>>=
          p.next <- prev.next;
          prev.next <- Some p;
        )


  let dequeue glr =
    match glr.top with
    | None -> None
    | Some path as ret ->
        glr.top <- path.next;
        ret

end


@
\subsection{Reduction worklist algorithm}
<<ml>>=

module RWL : sig

  val addTopmostParser
    : 'result glr
    -> StackNode.t
    -> unit

  val enqueueReductions
    : 'result glr
    -> StackNode.t
    -> ParseTables.action_entry
    -> SiblingLink.t option
    -> int

  val processWorklist
    : 'result glr
    -> ParseTables.term_index
    -> Lexing.position
    -> unit

  val shiftTerminals
    : 'result glr
    -> ParseTables.term_index
    -> SemanticValue.t
    -> SourceLocation.t
    -> unit

end = struct


@
  Add a new parser to the [[active_parsers]] list, maintaining
  related invariants.
<<ml>>=
  let addTopmostParser glr parsr =
    assert (StackNode.checkLocalInvariants parsr);

    Arraystack.push parsr glr.active_parsers;
    StackNode.inc_refcnt parsr


@
  Same argument meanings as for [[recursiveEnqueue]].
<<ml>>=
  let rec collectPathLink glr proto popsRemaining currentNode mustUseLink linkToAdd =
    proto.sibLinks.(popsRemaining) <- linkToAdd;
    proto.symbols .(popsRemaining) <- StackNode.getNodeSymbol glr currentNode;

    recursiveEnqueue glr proto popsRemaining linkToAdd.sib (
      match mustUseLink with
      | Some link when link == linkToAdd ->
          None
      | _ ->
@
          Consume must-use link.
<<ml>>=
          mustUseLink
    )

@
  Recursive depth-first enumeration of paths.
<<ml>>=
  and recursiveEnqueue glr
    proto         (* prototype path, with path so far *)
    popsRemaining (* # of links yet to traverse to find a full path *)
    currentNode   (* node we're at in the path *)
    mustUseLink   (* link the path must use (if not None) *)
  =
    if popsRemaining = 0 then (
@
      Found path.

      Must have used the link.
<<ml>>=
      match mustUseLink with
      | Some _ ->
@
          Do nothing.
<<ml>>=
          ()

      | None ->
@
          Copy the prototype path, it's the one we want.
<<ml>>=
          Path.insert_copy glr proto currentNode

    ) else (
@
      Explore [[currentNode]]'s siblings.
<<ml>>=
      collectPathLink glr proto (popsRemaining - 1) currentNode mustUseLink currentNode.firstSib;

      List.iter (fun sibling ->
        collectPathLink glr proto (popsRemaining - 1) currentNode mustUseLink sibling
      ) currentNode.leftSiblings
    )


  let enqueueReduceAction glr parsr action mustUseLink =
    let prodIndex = ParseTables.decodeReduce glr.tables action parsr.state in
@
    Production info.
<<ml>>=
    let rhsLen = ParseTables.getProdInfo_rhsLen glr.tables prodIndex in
    assert (rhsLen >= 0);       (* paranoia *)
@
    Make a prototype path; used to control recursion.
<<ml>>=
    let proto = Path.create glr parsr.state prodIndex rhsLen in
    assert (Path.ensureRhsLen proto rhsLen);
@
    Kick off the recursion.
<<ml>>=
    recursiveEnqueue glr proto rhsLen parsr mustUseLink;
@
    Deallocate prototype.
<<ml>>=
    Path.delete glr proto


@
  Returns number of actions.
<<ml>>=
  let rec enqueueReductions glr parsr action mustUseLink =
    assert (StackNode.checkLocalInvariants parsr);

    if ParseTables.isShiftAction glr.tables action then (
@
      Do nothing, only looking for reductions.
<<ml>>=
      1
    ) else if ParseTables.isReduceAction glr.tables action then (
      enqueueReduceAction glr parsr action mustUseLink;
      1
    ) else if ParseTables.isErrorAction glr.tables action then (
@
      Parser just dies.
<<ml>>=
      0
    ) else (
@
      Ambiguous; check for reductions in list of actions.
<<ml>>=
      let firstEntry = ParseTables.decodeAmbigAction glr.tables action parsr.state in
      let numEntries = (ParseTables.getAmbigEntry glr.tables firstEntry :> int) in

      for i = 1 to numEntries do
        let entry = ParseTables.getAmbigEntry glr.tables (firstEntry + i) in
@
        Ignore return value because I know it will be 1.
<<ml>>=
        ignore (enqueueReductions glr parsr entry mustUseLink);
      done;

      numEntries
    )


  let findTopmostParser glr state =
@
    Always using the \textit{not} [[USE_PARSER_INDEX]] case.
<<ml>>=
    Arraystack.find (fun n -> n.state = state) glr.active_parsers


  let canMakeProgress glr tokType parsr =
    let entry = ParseTables.getActionEntry glr.tables parsr.state tokType in

    ParseTables.isShiftAction glr.tables entry
      || ParseTables.isReduceAction glr.tables entry
      || not (ParseTables.isErrorAction glr.tables entry)


  let shiftActive glr tokType leftSibling rightSibling lhsIndex sval start_p end_p =
    match StackNode.getLinkTo rightSibling leftSibling with
    | Some sibLink ->
@
        We already have a sibling link, don't need a new one.

        It is here that we are bringing the tops of two.
        alternative parses together (TREEBUILD).

        Dead tree optimisation.
<<ml>>=
        if not (canMakeProgress glr tokType rightSibling) then (
          if Options._trace_parse () then
            Printf.printf "avoided a merge by noticing the state was dead\n";
          User.deallocateSemanticValue glr.userAct (StackNode.getNodeSymbol glr rightSibling) sval;
        ) else (
@
          Call user's merge code.
<<ml>>=
          sibLink.sval <- User.mergeAlternativeParses glr.userAct lhsIndex sibLink.sval sval;
        );
@
        Ok, done.
<<ml>>=
        None
@
        Didn't add a link, no potential for new paths.
<<ml>>=

    | None ->
@
        We get here if there is no suitable sibling link already
        existing; so add the link (and keep the ptr for loop below).
<<ml>>=
        let sibLink =
          StackNode.addSiblingLink rightSibling leftSibling sval start_p end_p
        in
@
        Adding a new sibling link may have introduced additional opportunities
        to do reductions from parsers we thought we were finished with.

        What's more, it's not just the parser ([[rightSibling]]) we added the
        link to -- if [[rightSibling]]'s item set contains $A \to \alpha . B
        \beta$ and $B \to \phi$ (so $A$'s item set also has $B \to .$), then we
        reduced it (if lookahead okay), so [[rightSibling]] now has another
        left sibling with $A \to \alpha B . \beta$. We need to let this sibling
        re-try its reductions also.

        So, the strategy is to let all 'finished' parsers re-try reductions, and
        process those that actually use the just-added link.

        we don't have to recompute if nothing else points at
        [[rightSibling]]; the reference count is always at least 1 because we
        found it on the "active parsers" worklist.
<<ml>>=
        if rightSibling.referenceCount > 1 then (
@
          Since we added a new link *all* determinDepths might
          be compromised; iterating more than once should be very
          rare (and this code path should already be unusual).
<<ml>>=
          let changes = ref true in
          let iters   = ref 0 in

          while !changes do
            changes := false;
            Arraystack.iter (fun parsr ->
              let newDepth = StackNode.computeDeterminDepth parsr in
              if newDepth <> parsr.determinDepth then (
                changes := true;
                parsr.determinDepth <- newDepth;
              )
            ) glr.active_parsers;
            incr iters;
@
            Protect against infinite loop.
<<ml>>=
            assert (!iters < 1000);     
          done
        );
@
        Inform the caller that a new sibling link was added.
<<ml>>=
        Some sibLink


  let shiftNew glr tokType leftSibling rightSiblingState sval start_p end_p =
@
    Not already active parser in this state, so make one.
<<ml>>=
    let rightSibling = StackNode.make glr rightSiblingState in
@
    Add link.
<<ml>>=
    ignore (StackNode.addSiblingLink rightSibling leftSibling sval start_p end_p);
@
    Extend frontier.
<<ml>>=
    addTopmostParser glr rightSibling;
@
    Enqueue this new parser's reductions.
<<ml>>=
    let action = ParseTables.getActionEntry glr.tables rightSibling.state tokType in
    ignore (enqueueReductions glr rightSibling action None(*siblink*));
@
    Caller doesn't need to do anything more.
<<ml>>=
    None


  let shiftNonterminal glr tokType leftSibling lhsIndex sval start_p end_p =
@
    Consult goto table to find where to go upon "shifting" the nonterminal.
<<ml>>=
    let rightSiblingState =
      ParseTables.getGoto glr.tables leftSibling.state lhsIndex
    in

    if Options._trace_parse () then
      Printf.printf "state %d, %s nonterm %d (%s), to state %d\n"
        (leftSibling.state :> int)
        (Colour.cyan "shift")
        (lhsIndex :> int)
        (User.nonterminalName glr.userAct lhsIndex)
        (rightSiblingState :> int);
@
    Is there already an active parser with this state?
<<ml>>=
    match findTopmostParser glr rightSiblingState with
    | Some rightSibling ->
        shiftActive glr tokType leftSibling rightSibling lhsIndex sval start_p end_p

    | None ->
        shiftNew glr tokType leftSibling rightSiblingState sval start_p end_p


  let rec recursiveProcess glr tokType start_p path =
@
    Info about the production.
<<ml>>=
    let rhsLen   = ParseTables.getProdInfo_rhsLen   glr.tables path.prodIndex in
    let lhsIndex = ParseTables.getProdInfo_lhsIndex glr.tables path.prodIndex in

    if Options._trace_parse () then
      Printf.printf "state %d, %s by production %d (rhsLen=%d), \
                     back to state %d\n"
        (path.startStateId :> int)
        (Colour.cyan "reduce")
        path.prodIndex
        rhsLen
        (path.leftEdgeNode.state :> int);

    if Options._accounting () then
      glr.stats.nondetReduce <- glr.stats.nondetReduce + 1;
@
    Record location of left edge; initially is location of
    the lookahead token.
<<ml>>=
    let leftEdge = ref start_p in
    let rightEdge = ref Lexing.dummy_pos in
@
    Before calling the user, duplicate any needed values.
<<ml>>=
    for i = rhsLen - 1 downto 0 do
      let sib = path.sibLinks.(i) in
@
      Put a copy of the sval in the array that will be passed to the user.
<<ml>>=
      glr.toPass.(i) <-
        User.duplicateSemanticValue glr.userAct
          path.symbols.(i) sib.sval;

      if Options._trace_parse () then
        Printf.printf "toPass[%d] = %s\n" i (Id.get glr.toPass.(i));

      if sib.start_p != Lexing.dummy_pos then
        leftEdge := sib.start_p;
      if !rightEdge == Lexing.dummy_pos && sib.end_p != Lexing.dummy_pos then
        rightEdge := sib.end_p;
    done;
@
    Invoke user's reduction action (TREEBUILD).
<<ml>>=
    begin try
      let sval =
        User.reductionAction glr.userAct
          path.prodIndex glr.toPass !leftEdge !rightEdge
      in
@
      Did user want to keep?
<<ml>>=
      if not (User.keepNontermValue glr.userAct lhsIndex sval) then
        keep_cancel ();

      if Options._trace_parse () then
        Printf.printf "result: %s%s %s\n"
          (User.nonterminalName glr.userAct lhsIndex)
          (Id.get sval)
          (User.showNontermValue glr.userAct lhsIndex sval);
@
      Shift the nonterminal, [[sval]].
<<ml>>=
      let newLink =
        shiftNonterminal glr tokType path.leftEdgeNode lhsIndex sval
          !leftEdge !rightEdge
      in

      if newLink != None then
@
        For each 'finished' parser, enqueue actions enabled by the new link.
<<ml>>=
        Arraystack.iter (fun parsr ->
          let action =
            ParseTables.getActionEntry glr.tables
              parsr.state tokType
          in
          ignore (enqueueReductions glr parsr action newLink)
        ) glr.active_parsers

    with UserActions.Cancel reason ->
@
      Cancelled; drop on floor.
<<ml>>=
      ()
    end;
@
    We dequeued it above, and are now done with it, so recycle
    it for future use.
<<ml>>=
    Path.delete glr path


  let rec processWorklist glr tokType start_p =
    match Path.dequeue glr with
    | None ->
@
        Nothing to do.
<<ml>>=
        ()

    | Some top ->
@
        Process the enabled reductions in priority order.
<<ml>>=
        recursiveProcess glr tokType start_p top;
        processWorklist glr tokType start_p


  let findShift tables tokType action state =
@
    Consult action table, looking for shifts.
<<ml>>=
    if ParseTables.isShiftAction tables action then (
@
      Unambiguous shift.
<<ml>>=
      ParseTables.decodeShift tables action tokType
    ) else if ParseTables.isReduceAction tables action
           || ParseTables.isErrorAction tables action then (
@
      Unambiguous reduction or error.
<<ml>>=
      ParseTables.invalid_state
    ) else (
@
      Nondeterministic.
<<ml>>=
      let firstEntry = ParseTables.decodeAmbigAction tables action state in
      let numEntries = (ParseTables.getAmbigEntry tables firstEntry :> int) in

      let newState = ref ParseTables.invalid_state in
      let i = ref 1 in
      while !i <> numEntries do
        let action = ParseTables.getAmbigEntry tables (firstEntry + !i) in
        incr i;
        if ParseTables.isShiftAction tables action then (
@
          A shift was among the conflicted actions.
<<ml>>=
          newState := ParseTables.decodeShift tables action tokType;

          (* "break" *)
          i := numEntries
        )
      done;

      !newState
    )


  let shiftTerminals glr tokType tokSval tokSloc =
    glr.globalNodeColumn <- glr.globalNodeColumn + 1;
@
    Move all parsers from [[active_parsers]] to [[prev_active]].
<<ml>>=
    assert (Arraystack.is_empty glr.prev_active);
    Arraystack.swap glr.prev_active glr.active_parsers;
    assert (Arraystack.is_empty glr.active_parsers);
@
    For token multi-yield.
<<ml>>=
    let prev = ref SiblingLink.null in

    Arraystack.iter (fun leftSibling ->
@
      Take the node from [[prev_active]]; the refcount transfers
      from [[prev_active]] to (local variable) [[leftSibling]].
<<ml>>=
      assert (leftSibling.referenceCount >= 1);   (* for the local *)
      let state = leftSibling.state in
@
      Can this parser shift?
<<ml>>=
      let action = ParseTables.getActionEntry glr.tables state tokType in
@
      If we find a shift, this will be set to something valid.
<<ml>>=
      let newState = findShift glr.tables tokType action state in

      if newState <> ParseTables.invalid_state then (
@
        Found a shift.
<<ml>>=

        if Options._accounting () then
          glr.stats.nondetShift <- glr.stats.nondetShift + 1;

        if Options._trace_parse () then
          Printf.printf "state %d, %s token %s, to state %d\n"
            (state :> int)
            (Colour.cyan "shift")
            (User.terminalName glr.userAct tokType)
            (newState :> int);
@
        Already a parser in this state?
<<ml>>=
        let rightSibling =
          match findTopmostParser glr newState with
          | Some rs ->
@
              Use existing.
<<ml>>=
              rs
          | None ->
@
              Must make a new stack node.
<<ml>>=
              let rs = StackNode.make glr newState in
@
              Add it to active parsers.
<<ml>>=
              addTopmostParser glr rs;
@
              Use new.
<<ml>>=
              rs
        in
@
        Semantic value for this token.
<<ml>>=
        prev :=
          if !prev == SiblingLink.null then (
@
              Usual case.
<<ml>>=
              StackNode.addSiblingLink rightSibling leftSibling
                tokSval (fst tokSloc) (snd tokSloc)

          ) else (
@
              The [[sval]] we just grabbed has already been claimed by
              [[prev.sval]]; get a fresh one by duplicating the latter.
<<ml>>=
              let sval =
                User.duplicateTerminalValue glr.userAct
                  tokType !prev.sval
              in
@
              Add sibling link now.
<<ml>>=
              StackNode.addSiblingLink rightSibling leftSibling
                sval !prev.start_p !prev.end_p
          );
@
        Adding this sibling link cannot violate the [[determinDepth]]
        invariant of some other node, because all of the nodes created
        or added-to during shifting do not have anything pointing at
        them, so in particular nothing points to [[rightSibling]]; a simple
        check of this is to check the reference count and verify it is 1,
        the 1 being for the [[active_parsers]] list it is on.
<<ml>>=
        assert (rightSibling.referenceCount = 1);
      );
@
      Pending decrement of [[leftSibling]], which is about to go out of scope.
<<ml>>=
      StackNode.dec_refcnt glr leftSibling;
    ) glr.prev_active;

    Arraystack.clear glr.prev_active

end

@
\subsection{Common to GLR and LR Parser cores}
<<ml>>=

module type ParserCore = sig

  val parseToken
    : 'result glr
    -> ParseTables.term_index
    -> SemanticValue.t
    -> SourceLocation.t
    -> unit

end

let parse_error ?reason glr tokType tokSloc lastToDie =
  if Options._error_verbose () then (
    if lastToDie <> ParseTables.invalid_state then (
      Printf.printf "In state %d, I expected one of these tokens:\n"
        (lastToDie :> int);
      ParseTables.iter_terms glr.tables (fun i ->
        let act = ParseTables.getActionEntry glr.tables lastToDie i in
        if not (ParseTables.isErrorAction glr.tables act) then
          Printf.printf "  [%d] %s\n"
            (i :> int)
            (User.terminalName glr.userAct i);
      )
    ) else (
      Printf.printf "(expected-token info not available due \
                     to nondeterministic mode)\n"
    );

    Printf.printf (*loc*) "Parse error (state %d) at %s\n"
      (lastToDie :> int)
      (User.terminalName glr.userAct tokType);
    match reason with
    | None -> ()
    | Some reason ->
        Printf.printf "Last reduction was cancelled because: %s\n" reason
  );

  raise (Located (tokSloc,
    ParseError (lastToDie, tokType),
    User.terminalName glr.userAct tokType
  ))

@
\subsection{Non-deterministic parser core}
<<ml>>=

module GLR : ParserCore = struct

  let nondeterministicParseToken glr tokType tokSval tokSloc =
    let lastToDie = ref ParseTables.invalid_state in
@
    Seed the reduction worklist by analysing the top nodes.
<<ml>>=
    Arraystack.iter (fun parsr ->
      let action = ParseTables.getActionEntry glr.tables parsr.state tokType in
      let actions = RWL.enqueueReductions glr parsr action None(*sibLink*) in

      if actions = 0 then (
        if Options._trace_parse () then
          Printf.printf "parser in state %d died\n"
            (parsr.state :> int);
        lastToDie := parsr.state
      )
    ) glr.active_parsers;
@
    Drop into worklist processing loop.
<<ml>>=
    RWL.processWorklist glr tokType (fst tokSloc);
@
    Do all shifts last.
<<ml>>=
    RWL.shiftTerminals glr tokType tokSval tokSloc;
@
    Error?
<<ml>>=
    if Arraystack.is_empty glr.active_parsers then
      parse_error glr tokType tokSloc !lastToDie
@
  Pulled out so I can use this block of statements in several places.
<<ml>>=


  let parseToken glr tokType tokSval tokSloc =
    let open Lexerint in
@
    Raises [[ParseError]] on failure.
<<ml>>=
    nondeterministicParseToken glr tokType tokSval tokSloc;
@
    Last token?
<<ml>>=
    if tokType = ParseTables.eof_term then
      raise End_of_file       (* "break" *)

end

@
\subsection{Mini-LR core}
<<ml>>=

module LR : ParserCore = struct

  let rec parseToken glr tokType tokSval tokSloc =
    let parsr = ref (Arraystack.top glr.active_parsers) in
    assert (!parsr.referenceCount = 1);

    let action =
      ParseTables.getActionEntry_noError
        glr.tables !parsr.state tokType
    in

    if ParseTables.isReduceAction glr.tables action then (
@
      Can reduce unambiguously.
<<ml>>=
      let prodIndex =
        ParseTables.decodeReduce
          glr.tables action !parsr.state
      in

      if Options._accounting () then
        glr.stats.detReduce <- glr.stats.detReduce + 1;

      let rhsLen = ParseTables.getProdInfo_rhsLen glr.tables prodIndex in

      if rhsLen <= !parsr.determinDepth then (
        let lhsIndex = ParseTables.getProdInfo_lhsIndex glr.tables prodIndex in

        let startStateId = !parsr.state in

        let leftEdge = ref (fst tokSloc) in
        let rightEdge = ref Lexing.dummy_pos in

        assert (rhsLen <= Array.length glr.toPass);
@
        Loop for arbitrary [[rhsLen]].

        Pop off [[rhsLen]] stack nodes, collecting as many semantic
        values into [[toPass]].

        NOTE: This loop is the innermost inner loop of the entire
        parser engine -- even \textit{one} branch inside the loop body
        costs about 30\% end-to-end performance loss!
<<ml>>=
        for i = rhsLen - 1 downto 0 do
@
          Grab the (only) sibling of [[parsr]].
<<ml>>=
          let sib = !parsr.firstSib in
@
          Store its semantic value it into array that will be
          passed to user's routine.  Note that there is no need to
          [[dup()]] this value, since it will never be passed to
          another action routine (avoiding that overhead is
          another advantage to the LR mode).
<<ml>>=
          glr.toPass.(i) <- sib.sval;
          if Options._trace_parse () then
            Printf.printf "toPass[%d] = %s\n" i (Id.get glr.toPass.(i));
@
          If it has a valid source location, grab it.
<<ml>>=
          if sib.start_p != Lexing.dummy_pos then
            leftEdge := sib.start_p;
          if !rightEdge == Lexing.dummy_pos && sib.end_p != Lexing.dummy_pos then
            rightEdge := sib.end_p;
@
          Pop [[parsr]] and move to next one.
<<ml>>=
          Objpool.dealloc glr.stackNodePool !parsr;
          let prev = !parsr in
          parsr := sib.sib;

          assert (!parsr.referenceCount = 1);
          assert (prev.referenceCount = 1);
@
          Adjust a couple things about [[prev]] reflecting
          that it has been deallocated.
<<ml>>=
          if Options._accounting () then (
            glr.stats.numStackNodes <- glr.stats.numStackNodes - 1;
          );
          prev.firstSib.sib <- StackNode.null;

          assert (!parsr.referenceCount = 1);
        done;
@
        Now, do an abbreviated [[glrShiftNonterminal]].
<<ml>>=
        let newState = ParseTables.getGoto glr.tables !parsr.state lhsIndex in

        if Options._trace_parse () then
          Printf.printf "state %d, (unambig) %s by %d (len=%d), \
                         back to %d then out to %d\n"
            (startStateId :> int)
            (Colour.cyan "reduce")
            prodIndex
            rhsLen
            (!parsr.state :> int)
            (newState :> int);
@
        Call the user's action function (TREEBUILD).
<<ml>>=
        let sval =
          try
            let sval =
              User.reductionAction glr.userAct prodIndex glr.toPass
                !leftEdge !rightEdge
            in
@
            Does the user want to keep it?
<<ml>>=
            if not (User.keepNontermValue glr.userAct lhsIndex sval) then
              keep_cancel ();
            if Options._trace_parse () then
              Printf.printf "result: %s %s\n"
                (Id.get sval)
                (User.showNontermValue glr.userAct lhsIndex sval);

            sval
          with UserActions.Cancel reason ->
            parse_error ~reason glr tokType tokSloc newState
        in
@
        The sole reference is the [[parsr]] variable.
<<ml>>=
        assert (!parsr.referenceCount = 1);
@
        Push new state.
<<ml>>=
        let newNode = StackNode.make glr newState in

        StackNode.addFirstSiblingLink_no_refcnt newNode !parsr sval
          !leftEdge !rightEdge;

        assert (!parsr.referenceCount = 1);
@
        Replace old topmost parser with [[newNode]].
<<ml>>=
        assert (Arraystack.length glr.active_parsers = 1);
        Arraystack.set glr.active_parsers 0 newNode;
        StackNode.inc_refcnt newNode;
        assert (newNode.referenceCount = 1);
@
        We have not shifted a token, so again try to use
        the deterministic core.
<<ml>>=
        parseToken glr tokType tokSval tokSloc
      ) else (
@
        Deterministic depth insufficient: use GLR.
<<ml>>=
        GLR.parseToken glr tokType tokSval tokSloc
      )

    ) else if ParseTables.isShiftAction glr.tables action then (
@
      Can shift unambiguously.
<<ml>>=
      let newState = ParseTables.decodeShift glr.tables action tokType in
      if Options._accounting () then
        glr.stats.detShift <- glr.stats.detShift + 1;

      if Options._trace_parse () then
        Printf.printf "state %d, (unambig) %s token %d, to state %d\n"
          (!parsr.state :> int)
          (Colour.cyan "shift")
          (tokType :> int)
          (newState :> int);

      glr.globalNodeColumn <- glr.globalNodeColumn + 1;

      let rightSibling = StackNode.make glr newState in

      StackNode.addFirstSiblingLink_no_refcnt rightSibling !parsr
        tokSval (fst tokSloc) (snd tokSloc);
@
      Replace [[parsr]] with [[rightSibling]].
<<ml>>=
      assert (Arraystack.length glr.active_parsers = 1);
      Arraystack.set glr.active_parsers 0 rightSibling;

      assert (!parsr.referenceCount = 1);
      assert (rightSibling.referenceCount = 0);

      rightSibling.referenceCount <- 1;
@
      Last token?
<<ml>>=
      if tokType = ParseTables.eof_term then
        raise End_of_file       (* "break" *)

    ) else (
@
      Error or ambig; not deterministic.
<<ml>>=
      GLR.parseToken glr tokType tokSval tokSloc
    )

end

@
\subsection{Debugging and tracing}
<<ml>>=

let nodeSummary node =
  Printf.sprintf "%d[%d]" (node.state :> int) node.referenceCount


let rec innerStackSummary printed node =
  if List.memq node !printed then (
@
    Already printed.
<<ml>>=
    "(rep:" ^ nodeSummary node ^ ")"

  ) else (
@
    Remember that we've now printed [[node]].
<<ml>>=
    printed := node :: !printed;

    if StackNode.hasZeroSiblings node then (
@
      No siblings.
<<ml>>=
      nodeSummary node

    ) else if StackNode.hasOneSibling node then (
@
      One sibling.
<<ml>>=
      nodeSummary node ^ "-" ^
      innerStackSummary printed node.firstSib.sib

    ) else (
@
      Multiple siblings.

      Force order of eval.
<<ml>>=
      let nodeSummary = nodeSummary node in
      let firstSummary = innerStackSummary printed node.firstSib.sib in
      let siblingsSummary =
        List.fold_left (fun acc link ->
          acc ^ "|" ^ innerStackSummary printed link.sib
        ) "" node.leftSiblings
      in

      Printf.sprintf "%s-(%s%s)" nodeSummary firstSummary siblingsSummary

    )
  )

@
Print stack contents summary.
<<ml>>=
let stackSummary glr =
@
  Nodes already printed.
<<ml>>=
  let printed = ref [] in
@
  Loop/fold.
<<ml>>=
  let len = Arraystack.length glr.active_parsers in
  let rec loop acc i =
    if i > len - 1 then
@
      Done.
<<ml>>=
      acc
    else
      let n = Arraystack.nth glr.active_parsers i in
      let summary =
        Printf.sprintf "%s (%d: %s)"
          acc i (innerStackSummary printed n)
      in

      loop summary (i + 1)
  in

  loop "" 0

@
\subsection{Main parser loop}

This function is the core of the parser, and its performance is critical to the
end-to-end performance of the whole system. It does not actually return, but it
has the same return type as the main entry point.
<<ml>>=

let rec main_loop (glr : 'result glr) lexer token : 'result =
  if Options._trace_parse () then (
    let open Lexerint in
    let tokType = lexer.index token in

    Printf.printf "---- processing token %s, %d active parsers ----\n"
      (User.terminalName glr.userAct tokType)
      (Arraystack.length glr.active_parsers);
    Printf.printf "Stack:%s\n" (stackSummary glr);
  );
@
  Classify and decompose current token.
<<ml>>=
  let tokType, tokSval, tokSloc =
    User.reclassifyToken glr.userAct lexer token
  in

  begin try
    if Options._use_mini_lr () && Arraystack.length glr.active_parsers = 1 then
@
      Try deterministic parsing.
<<ml>>=
      LR.parseToken glr tokType tokSval tokSloc
    else
@
      Mini LR core disabled, use full GLR.
<<ml>>=
      GLR.parseToken glr tokType tokSval tokSloc;
  with
  | Located _
  | End_of_file as e ->
@
      Propagate internal exceptions and ones
      already wrapped in [[Located]].
<<ml>>=
      raise e
  | e ->
      raise (Located (tokSloc, e, Printexc.get_backtrace ()))
  end;
@
  Parse next token.
<<ml>>=
  main_loop glr lexer Lexerint.(lexer.token ())

@
\subsection{Entry and exit of GLR parser}

Used to extract the svals from the nodes just under the start symbol reduction.
<<ml>>=

let grabTopSval glr node =
  let sib = StackNode.getUniqueLink node in
  let ret = sib.sval in
  sib.sval <-
    User.duplicateSemanticValue glr.userAct
      (StackNode.getNodeSymbol glr node) sib.sval;

  (* TRSACTION("dup'd " << ret << " for top sval, yielded " << sib->sval); *)

  ret


let cleanupAfterParse (glr : 'result glr) : 'result =
  if Options._trace_parse () then
    Printf.printf "==== parse succeeded ====\n";

  if not (Arraystack.length glr.active_parsers = 1) then (
    Printf.printf "parsing finished with %d active parsers!\n"
      (Arraystack.length glr.active_parsers);
    raise (ParseError (
      ParseTables.invalid_state,
      ParseTables.invalid_term
    ))
  ) else (
    let last = Arraystack.top glr.active_parsers in
@
    Prepare to run final action.
<<ml>>=
    let arr =
      Array.init 2 (function
        | 0 ->
            let nextToLast = (StackNode.getUniqueLink last).sib in
@
            Semantic value we want:
<<ml>>=
            grabTopSval glr nextToLast
        | 1 ->
@
            [[EOF]]'s sval:
<<ml>>=
            grabTopSval glr last
        | _ -> assert false
      )
    in
@
    Reduce.
<<ml>>=
    let finalProductionIndex =
      ParseTables.getFinalProductionIndex glr.tables
    in
    let treeTop =
      SemanticValue.obj (
        User.reductionAction glr.userAct finalProductionIndex arr
          Lexing.dummy_pos Lexing.dummy_pos
      )
    in
@
    Before pool goes away..
<<ml>>=
    Arraystack.iter (StackNode.dec_refcnt glr) glr.active_parsers;

    treeTop
  )


let parse (glr : 'result glr) lexer : 'result =
  Id.reset ();

  if glr.globalNodeColumn <> 0 then
    failwith "cannot reuse glr object for multiple parses";

  begin
    let startState = ParseTables.getStartState glr.tables in
    let first = StackNode.make glr startState in
    RWL.addTopmostParser glr first;
  end;

  if Options._trace_parse () then
    Printf.printf "==== starting parse ====\n";
@
  Main parsing loop; this function never returns normally.
<<ml>>=
  try
@
    Get first token and start parsing.
<<ml>>=
    main_loop glr lexer Lexerint.(lexer.token ())

  with End_of_file ->
@
    End of parse.
<<ml>>=
    cleanupAfterParse glr

@
\subsection{Creating the GLR parser object}
<<ml>>=

let makePath maxRhsLen () = {
  sibLinks     = Array.make maxRhsLen SiblingLink.null;
  symbols      = Array.make maxRhsLen ParseTables.invalid_symbol;
  startStateId = ParseTables.invalid_state;
  prodIndex    = -1;
  rhsLen       = -1;
  startColumn  = -1;
  leftEdgeNode = StackNode.null;
  next         = None;
}


let computeMaxRhsLen tables =
  CoreInt.fold_left (fun len i ->
    max len (ParseTables.getProdInfo_rhsLen tables i)
  ) 0 0 (ParseTables.getNumProds tables - 1)


let create userAct tables =
  let maxRhsLen = computeMaxRhsLen tables in

  {
    userAct;
    tables;
    top                 = None;
    toPass              = Array.make maxRhsLen SemanticValue.null;
    pathPool		= Objpool.make (makePath maxRhsLen);
    active_parsers      = Arraystack.create ();
    prev_active         = Arraystack.create ();
    stackNodePool       = Objpool.make StackNode.create;
    globalNodeColumn    = 0;
    stats = {
      numStackNodes = 0;
      maxStackNodes = 0;
      detShift      = 0;
      detReduce     = 0;
      nondetShift   = 0;
      nondetReduce  = 0;
    };
  }


let stats glr = {
  num_stack_nodes	= glr.stats.numStackNodes;
  max_stack_nodes	= glr.stats.maxStackNodes;
  det_shift		= glr.stats.detShift;
  det_reduce		= glr.stats.detReduce;
  nondet_shift		= glr.stats.nondetShift;
  nondet_reduce		= glr.stats.nondetReduce;
}
